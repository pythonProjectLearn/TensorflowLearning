{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Different Layers\n",
    "\n",
    "\n",
    "We will illustrate how to use different types of layers in TensorFlow\n",
    "\n",
    "下面介绍不同层的使用\n",
    "\n",
    "The layers of interest are:\n",
    "1. Convolutional Layer\n",
    "2. Activation Layer \n",
    "3. Max-Pool Layer\n",
    "4. Fully Connected Layer\n",
    "\n",
    "We will generate two different data sets for this script, a 1-D data set (row of data) and a 2-D data set (similar to picture)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 拼接\n",
    "\n",
    "在2D图上，0轴相当于x轴，1轴相当于y轴；0轴拼接，就是0轴与0轴粘在一起；1轴拼接，就是1轴与1轴粘在一起\n",
    "\n",
    "在3D图上，0轴是x轴（长），1轴是y轴（宽），2轴是z轴（高）\n",
    "\n",
    "TensorFlow提供两种类型的拼接：\n",
    "\n",
    "    tf.concat(values, axis, name='concat')：按照指定的已经存在的轴进行拼接\n",
    "\n",
    "    tf.stack(values, axis=0, name='stack')：按照指定的新建的轴进行拼接\n",
    "\n",
    "t1 = [[1, 2, 3], [4, 5, 6]]\n",
    "\n",
    "t2 = [[7, 8, 9], [10, 11, 12]]\n",
    "\n",
    "1. tf.concat([t1, t2], 0) ==> \n",
    "\n",
    "    [[1, 2, 3], \n",
    "    \n",
    "     [4, 5, 6], \n",
    "     \n",
    "     [7, 8, 9], \n",
    "     \n",
    "     [10, 11, 12]]\n",
    "\n",
    "2. tf.concat([t1, t2], 1) ==> \n",
    "\n",
    "    [[1, 2, 3, 7, 8, 9], \n",
    "\n",
    "      [4, 5, 6, 10, 11, 12]]\n",
    "\n",
    "\n",
    "\n",
    "3. tf.stack([t1, t2], 0)  ==> \n",
    "\n",
    "   在0轴上拼接，先在t1 t2上建立0轴，0轴的长度为1, \n",
    "\n",
    "   [[[1, 2, 3], \n",
    "   \n",
    "     [4, 5, 6]], \n",
    "     \n",
    "    [[7, 8, 9], \n",
    "    \n",
    "     [10, 11, 12]]]\n",
    "\n",
    "4. tf.stack([t1, t2], 1)  ==> \n",
    "\n",
    "    [[[1, 2, 3], \n",
    "      [7, 8, 9]], \n",
    "      \n",
    "     [[4, 5, 6], \n",
    "     [10, 11, 12]]]\n",
    "\n",
    "5. tf.stack([t1, t2], 2)  ==> \n",
    "    [[[1, 7],     \n",
    "    \n",
    "      [2, 8], \n",
    "      \n",
    "      [3, 9]], \n",
    "    \n",
    "    [[4, 10], \n",
    "    \n",
    "     [5, 11], \n",
    "     \n",
    "     [6, 12]]]\n",
    "\n",
    "我们从shape角度看一下就很容易明白了\n",
    "\n",
    "t1 = [[1, 2, 3], [4, 5, 6]]\n",
    "\n",
    "t2 = [[7, 8, 9], [10, 11, 12]]\n",
    "\n",
    "tf.concat([t1, t2], 0)  # [2,3] + [2,3] ==> [4, 3]\n",
    "\n",
    "tf.concat([t1, t2], 1)  # [2,3] + [2,3] ==> [2, 6]\n",
    "\n",
    "tf.stack([t1, t2], 0)   # [2,3] + [2,3] ==> [2*,2,3] # 新建轴0，在轴0上拼接\n",
    "\n",
    "tf.stack([t1, t2], 1)   # [2,3] + [2,3] ==> [2,2*,3]\n",
    "\n",
    "tf.stack([t1, t2], 2)   # [2,3] + [2,3] ==> [2,3,2*]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 抽取\n",
    "\n",
    "\n",
    "\n",
    "    tf.slice(input_, begin, size, name=None)：按照指定的下标范围抽取连续区域的子集\n",
    "\n",
    "    tf.gather(params, indices, validate_indices=None, name=None)：按照指定的下标集合从axis=0中抽取子集，适合抽取不连续区域的子集\n",
    "\n",
    "input = [\n",
    "         \n",
    "         [[1, 1, 1], [2, 2, 2]],\n",
    "\n",
    "         [[3, 3, 3], [4, 4, 4]],\n",
    "         \n",
    "         [[5, 5, 5], [6, 6, 6]]\n",
    "       \n",
    "       ]\n",
    "         \n",
    "tf.slice(input, [1, 0, 0], [1, 1, 3]) ==> [[[3, 3, 3]]]\n",
    "\n",
    "tf.slice(input, [1, 0, 0], [1, 2, 3]) ==> [[[3, 3, 3],\n",
    "                                            [4, 4, 4]]]\n",
    "                                            \n",
    "tf.slice(input, [1, 0, 0], [2, 1, 3]) ==> [[[3, 3, 3]],\n",
    "                                           [[5, 5, 5]]]\n",
    "                                           \n",
    "tf.gather(input, [0, 2]) ==> [[[1, 1, 1], [2, 2, 2]],\n",
    "                              [[5, 5, 5], [6, 6, 6]]]\n",
    "                              \n",
    "假设我们要从input中抽取[[[3, 3, 3]]]，这个输出在inputaxis=0的下标是1，axis=1的下标是0，axis=2的下标是0-2，所以begin=[1,0,0]，size=[1,1,3]。\n",
    "\n",
    "假设我们要从input中抽取[[[3, 3, 3], [4, 4, 4]]]，这个输出在inputaxis=0的下标是1，axis=1的下标是0-1，axis=2的下标是0-2，所以begin=[1,0,0]，size=[1,2,3]。\n",
    "\n",
    "假设我们要从input中抽取[[[3, 3, 3], [5, 5, 5]]]，这个输出在inputaxis=0的下标是1-2，axis=1的下标是0，axis=2的下标是0-2，所以begin=[1,0,0]，size=[2,1,3]。\n",
    "\n",
    "假设我们要从input中抽取[[[1, 1, 1], [2, 2, 2]],[[5, 5, 5], [6, 6, 6]]]，这个输出在input的axis=0的下标是[0, 2]，不连续，可以用tf.gather抽取。                              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 类型转化\n",
    "\n",
    "    tf.string_to_number(string_tensor, out_type=None, name=None): 将字符串转化为tf.float32（默认）和tf.int32\n",
    "\n",
    "    tf.to_double(x, name='ToDouble')：转化为tf.float64\n",
    "\n",
    "    tf.to_float(x, name='ToFloat')：转化为tf.float32\n",
    "\n",
    "    tf.to_int32(x, name='ToInt32')：转化为tf.int32\n",
    "\n",
    "    tf.to_int64(x, name='ToInt64')：转化为tf.int64\n",
    "\n",
    "    tf.cast(x, dtype, name=None)：转化为dtype指定的类型\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 形状转化\n",
    "\n",
    "    tf.reshape(tensor, shape, name=None)：转化为新shape，若有一个维度设置为-1，会自动推导"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SparseTensor\n",
    "\n",
    "TensorFlow使用三个dense tensor来表达一个sparse tensor：indices、values、dense_shape。\n",
    "\n",
    "假如我们有一个dense tensor：\n",
    "\n",
    " [[1, 0, 0, 0]\n",
    " [0, 0, 2, 0]\n",
    " [0, 0, 0, 0]]\n",
    "\n",
    "那么用SparseTensor表达这个数据对应的三个dense tensor如下：\n",
    "\n",
    "    indices：[[0, 0], [1, 2]]\n",
    "\n",
    "    values：[1, 2]\n",
    "\n",
    "    dense_shape：[3, 4]\n",
    "\n",
    "可以通过以下两种方法，将sparse tensor转化为dense tensor：\n",
    "\n",
    "    tf.sparse_to_dense(sparse_indices, output_shape, sparse_values, default_value=0, validate_indices=True, name=None)\n",
    "\n",
    "    tf.sparse_tensor_to_dense(sp_input, default_value=0, validate_indices=True, name=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 字符串操作\n",
    "\n",
    "拆分\n",
    "\n",
    "tf.string_split(source, delimiter=' ')\n",
    "\n",
    "source是一维数组，用于将一组字符串按照delimiter拆分为多个元素，返回值为一个SparseTensor。\n",
    "\n",
    "假如有两个字符串，source[0]是“hello world”，source[1]是“a b c”，那么输出结果如下：\n",
    "\n",
    "    st.indices： [0, 0; 0, 1; 1, 0; 1, 1; 1, 2]\n",
    "\n",
    "    st.values： ['hello', 'world', 'a', 'b', 'c']\n",
    "\n",
    "    st.dense_shape：[2, 3]\n",
    "\n",
    "拼接\n",
    "\n",
    "tf.string_join(inputs, separator=None, name=None)，用起来比较简单：\n",
    "\n",
    "tf.string_join([\"hello\", \"world\"], separator=\" \") ==> \"hello world\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自定义op函数\n",
    "通过tf.py_func(func, inp, Tout, stateful=True, name=None)可以将任意的python函数func转变为TensorFlow op。\n",
    "\n",
    "func接收的输入必须是numpy array，可以接受多个输入参数；输出也是numpy array，也可以有多个输出。inp传入输入值，Tout指定输出的基本数据类型。\n",
    "\n",
    "```\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "json_str_1 = '''\n",
    "    {\"name\": \"shuiping.chen\",\n",
    "    \"score\": 95,\n",
    "    \"department\": \"industrial engineering\",\n",
    "    \"rank\": 2\n",
    "    }\n",
    "'''\n",
    "json_str_2 = '''\n",
    "    {\"name\": \"zhuibing.dan\",\n",
    "    \"score\": 87,\n",
    "    \"department\": \"production engineering\",\n",
    "    \"rank\": 4\n",
    "    }\n",
    "'''\n",
    "\n",
    "input_array = np.array([json_str_1, json_str_2])\n",
    "\n",
    "def parse_json(json_str_array):\n",
    "    fea_dict_array = [ json.loads(item) for item in json_str_array ]\n",
    "    ret_feature = []\n",
    "    for fea_dict in fea_dict_array:\n",
    "        feature = [fea_dict[\"score\"], fea_dict[\"rank\"]]\n",
    "        ret_feature.append(feature)\n",
    "    return np.array(ret_feature, dtype=np.float32)\n",
    "\n",
    "parse_json_op = tf.py_func(parse_json, [input_array], tf.float32)\n",
    "sess = tf.Session()\n",
    "print sess.run(parse_json_op)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import random\n",
    "from tensorflow.python.framework import ops\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 1D数据在不同层中的使用\n",
    "```\n",
    "#---------------------------------------------------|\n",
    "#-------------------1D-data-------------------------|\n",
    "#---------------------------------------------------|\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 初始化网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create graph session \n",
    "ops.reset_default_graph()\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 设置种子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ensure reproducibility\n",
    "seed=13\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 设置模型中的固定参数\n",
    "\n",
    "1. 数据集的维度\n",
    "2. 卷积核的大小\n",
    "3. 池化的大小\n",
    "4. 移动窗口的尺度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters for the run\n",
    "data_size = 25\n",
    "conv_size = 5\n",
    "maxpool_size = 5\n",
    "stride_size = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 构建数据和占位符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate 1D data\n",
    "data_1d = np.random.normal(size=data_size)\n",
    "\n",
    "# Placeholder\n",
    "x_input_1d = tf.placeholder(dtype=tf.float32, shape=[data_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 构架卷积层\n",
    "\n",
    "因为tensorflow中的`conv2d()`是用于4D的数组，而创建的数据是1D的向量，所以要将1D扩展成4D才能使用这个函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#--------Convolution--------\n",
    "def conv_layer_1d(input_1d, my_filter,stride):\n",
    "    # TensorFlow's 'conv2d()' function only works with 4D arrays:\n",
    "    # [batch#, width, height, channels], we have 1 batch, and\n",
    "    # width = 1, but height = the length of the input, and 1 channel.\n",
    "    # So next we create the 4D array by inserting dimension 1's.\n",
    "    # 将 1D扩展成4D\n",
    "    input_2d = tf.expand_dims(input_1d, 0)\n",
    "    input_3d = tf.expand_dims(input_2d, 0)\n",
    "    input_4d = tf.expand_dims(input_3d, 3)\n",
    "    # Perform convolution with stride = 1, if we wanted to increase the stride,\n",
    "    # to say '2', then strides=[1,1,2,1]\n",
    "    # 卷积运算\n",
    "    convolution_output = tf.nn.conv2d(input_4d, filter=my_filter, strides=[1,1,stride,1], padding=\"VALID\")\n",
    "    # 去掉为1的轴，变回1D，因为激活函数只能对1D的数据继续运算\n",
    "    conv_output_1d = tf.squeeze(convolution_output)\n",
    "    return(conv_output_1d)\n",
    "\n",
    "# 初始化一个卷积核\n",
    "my_filter = tf.Variable(tf.random_normal(shape=[1,conv_size,1,1]))\n",
    "# 将卷积核用于4D的数据\n",
    "my_convolution_output = conv_layer_1d(x_input_1d, my_filter,stride=stride_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 卷积之后接一个激活函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#--------Activation--------\n",
    "# 激活函数relu只能对1D数据进行变换\n",
    "def activation(input_1d):\n",
    "    return(tf.nn.relu(input_1d))\n",
    "\n",
    "# Create activation layer\n",
    "my_activation_output = activation(my_convolution_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 激活之后最大池化，提取信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#--------Max Pool--------\n",
    "# 因为池化也是对4D的数据做处理，所以经过激活层之后，又要把数据从1D变回4D\n",
    "def max_pool(input_1d, width,stride):\n",
    "    # Just like 'conv2d()' above, max_pool() works with 4D arrays.\n",
    "    # [batch_size=1, width=1, height=num_input, channels=1]\n",
    "    input_2d = tf.expand_dims(input_1d, 0)\n",
    "    input_3d = tf.expand_dims(input_2d, 0)\n",
    "    input_4d = tf.expand_dims(input_3d, 3)\n",
    "    # Perform the max pooling with strides = [1,1,1,1]\n",
    "    # If we wanted to increase the stride on our data dimension, say by\n",
    "    # a factor of '2', we put strides = [1, 1, 2, 1]\n",
    "    # We will also need to specify the width of the max-window ('width')\n",
    "    pool_output = tf.nn.max_pool(input_4d, ksize=[1, 1, width, 1],\n",
    "                                 strides=[1, 1, stride, 1],\n",
    "                                 padding='VALID')\n",
    "    # 再把数据降为1D\n",
    "    pool_output_1d = tf.squeeze(pool_output)\n",
    "    return(pool_output_1d)\n",
    "\n",
    "my_maxpool_output = max_pool(my_activation_output, width=maxpool_size,stride=stride_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.8 池化之后接上全连接层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#--------Fully Connected--------\n",
    "def fully_connected(input_layer, num_outputs):\n",
    "    # First we find the needed shape of the multiplication weight matrix:\n",
    "    # The dimension will be (length of input) by (num_outputs)\n",
    "    # weight_shape是为了获得连接层的权重矩阵的shape\n",
    "    weight_shape = tf.squeeze(tf.stack([tf.shape(input_layer),[num_outputs]]))\n",
    "    # Initialize such weight\n",
    "    weight = tf.random_normal(weight_shape, stddev=0.1)\n",
    "    # Initialize the bias\n",
    "    bias = tf.random_normal(shape=[num_outputs])\n",
    "    # Make the 1D input array into a 2D array for matrix multiplication\n",
    "    input_layer_2d = tf.expand_dims(input_layer, 0)\n",
    "    # Perform the matrix multiplication and add the bias\n",
    "    full_output = tf.add(tf.matmul(input_layer_2d, weight), bias)\n",
    "    # Get rid of extra dimensionsnum_outputs\n",
    "    full_output_1d = tf.squeeze(full_output)\n",
    "    return(full_output_1d)\n",
    "\n",
    "my_full_output = fully_connected(my_maxpool_output, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> 1D Data <<<<\n",
      "Input = array of length 25\n",
      "Convolution w/ filter, length = 5, stride size = 1, results in an array of length 21:\n",
      "[-2.63576341 -1.11550486 -0.95571411 -1.69670296 -0.35699379  0.62266493\n",
      "  4.43316031  2.01364899  1.33044648 -2.30629659 -0.82916248 -2.63594174\n",
      "  0.76669347 -2.46465087 -2.2855041   1.49780679  1.6960566   1.48557389\n",
      " -2.79799461  1.18149185  1.42146575]\n",
      "\n",
      "Input = above array of length 21\n",
      "ReLU element wise returns an array of length 21:\n",
      "[ 0.          0.          0.          0.          0.          0.62266493\n",
      "  4.43316031  2.01364899  1.33044648  0.          0.          0.\n",
      "  0.76669347  0.          0.          1.49780679  1.6960566   1.48557389\n",
      "  0.          1.18149185  1.42146575]\n",
      "\n",
      "Input = above array of length 21\n",
      "MaxPool, window length = 5, stride size = 1, results in the array of length 17\n",
      "[ 0.          0.62266493  4.43316031  4.43316031  4.43316031  4.43316031\n",
      "  4.43316031  2.01364899  1.33044648  0.76669347  0.76669347  1.49780679\n",
      "  1.6960566   1.6960566   1.6960566   1.6960566   1.6960566 ]\n",
      "\n",
      "Input = above array of length 17\n",
      "Fully connected layer on all 4 rows with 5 outputs:\n",
      "[ 1.71536076 -0.72340977 -1.22485089 -2.5412786  -0.16338301]\n"
     ]
    }
   ],
   "source": [
    "# Run graph\n",
    "# Initialize Variables\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "feed_dict = {x_input_1d: data_1d}\n",
    "\n",
    "print('>>>> 1D Data <<<<')\n",
    "\n",
    "# Convolution Output\n",
    "print('Input = array of length %d' % (x_input_1d.shape.as_list()[0]))\n",
    "print('Convolution w/ filter, length = %d, stride size = %d, results in an array of length %d:' % \n",
    "      (conv_size,stride_size,my_convolution_output.shape.as_list()[0]))\n",
    "print(sess.run(my_convolution_output, feed_dict=feed_dict))\n",
    "\n",
    "# Activation Output\n",
    "print('\\nInput = above array of length %d' % (my_convolution_output.shape.as_list()[0]))\n",
    "print('ReLU element wise returns an array of length %d:' % (my_activation_output.shape.as_list()[0]))\n",
    "print(sess.run(my_activation_output, feed_dict=feed_dict))\n",
    "\n",
    "# Max Pool Output\n",
    "print('\\nInput = above array of length %d' % (my_activation_output.shape.as_list()[0]))\n",
    "print('MaxPool, window length = %d, stride size = %d, results in the array of length %d' %\n",
    "     (maxpool_size,stride_size,my_maxpool_output.shape.as_list()[0]))\n",
    "print(sess.run(my_maxpool_output, feed_dict=feed_dict))\n",
    "\n",
    "# Fully Connected Output\n",
    "print('\\nInput = above array of length %d' % (my_maxpool_output.shape.as_list()[0]))\n",
    "print('Fully connected layer on all 4 rows with %d outputs:' % \n",
    "      (my_full_output.shape.as_list()[0]))\n",
    "print(sess.run(my_full_output, feed_dict=feed_dict))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 2D数据在网络层中的使用\n",
    "```\n",
    "#---------------------------------------------------|\n",
    "#-------------------2D-data-------------------------|\n",
    "#---------------------------------------------------|\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reset Graph\n",
    "ops.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "\n",
    "# parameters for the run\n",
    "row_size = 10\n",
    "col_size = 10\n",
    "conv_size = 2\n",
    "conv_stride_size = 2\n",
    "maxpool_size = 2\n",
    "maxpool_stride_size = 1\n",
    "\n",
    "\n",
    "# ensure reproducibility\n",
    "seed=13\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)\n",
    "\n",
    "#Generate 2D data\n",
    "data_size = [row_size,col_size]\n",
    "data_2d = np.random.normal(size=data_size)\n",
    "\n",
    "#--------Placeholder--------\n",
    "x_input_2d = tf.placeholder(dtype=tf.float32, shape=data_size)\n",
    "\n",
    "# Convolution\n",
    "def conv_layer_2d(input_2d, my_filter,stride_size):\n",
    "    # TensorFlow's 'conv2d()' function only works with 4D arrays:\n",
    "    # [batch#, width, height, channels], we have 1 batch, and\n",
    "    # 1 channel, but we do have width AND height this time.\n",
    "    # So next we create the 4D array by inserting dimension 1's.\n",
    "    input_3d = tf.expand_dims(input_2d, 0)\n",
    "    input_4d = tf.expand_dims(input_3d, 3)\n",
    "    # Note the stride difference below!\n",
    "    convolution_output = tf.nn.conv2d(input_4d, filter=my_filter, \n",
    "                                      strides=[1,stride_size,stride_size,1], padding=\"VALID\")\n",
    "    # Get rid of unnecessary dimensions\n",
    "    conv_output_2d = tf.squeeze(convolution_output)\n",
    "    return(conv_output_2d)\n",
    "\n",
    "# Create Convolutional Filter\n",
    "my_filter = tf.Variable(tf.random_normal(shape=[conv_size,conv_size,1,1]))\n",
    "# Create Convolutional Layer\n",
    "my_convolution_output = conv_layer_2d(x_input_2d, my_filter,stride_size=conv_stride_size)\n",
    "\n",
    "#--------Activation--------\n",
    "def activation(input_1d):\n",
    "    return(tf.nn.relu(input_1d))\n",
    "\n",
    "# Create Activation Layer\n",
    "my_activation_output = activation(my_convolution_output)\n",
    "\n",
    "#--------Max Pool--------\n",
    "def max_pool(input_2d, width, height,stride):\n",
    "    # Just like 'conv2d()' above, max_pool() works with 4D arrays.\n",
    "    # [batch_size=1, width=given, height=given, channels=1]\n",
    "    input_3d = tf.expand_dims(input_2d, 0)\n",
    "    input_4d = tf.expand_dims(input_3d, 3)\n",
    "    # Perform the max pooling with strides = [1,1,1,1]\n",
    "    # If we wanted to increase the stride on our data dimension, say by\n",
    "    # a factor of '2', we put strides = [1, 2, 2, 1]\n",
    "    pool_output = tf.nn.max_pool(input_4d, ksize=[1, height, width, 1],\n",
    "                                 strides=[1, stride, stride, 1],\n",
    "                                 padding='VALID')\n",
    "    # Get rid of unnecessary dimensions\n",
    "    pool_output_2d = tf.squeeze(pool_output)\n",
    "    return(pool_output_2d)\n",
    "\n",
    "# Create Max-Pool Layer\n",
    "my_maxpool_output = max_pool(my_activation_output, \n",
    "                             width=maxpool_size, height=maxpool_size,stride=maxpool_stride_size)\n",
    "\n",
    "\n",
    "#--------Fully Connected--------\n",
    "def fully_connected(input_layer, num_outputs):\n",
    "    # In order to connect our whole W byH 2d array, we first flatten it out to\n",
    "    # a W times H 1D array.\n",
    "    flat_input = tf.reshape(input_layer, [-1])\n",
    "    # We then find out how long it is, and create an array for the shape of\n",
    "    # the multiplication weight = (WxH) by (num_outputs)\n",
    "    weight_shape = tf.squeeze(tf.stack([tf.shape(flat_input),[num_outputs]]))\n",
    "    # Initialize the weight\n",
    "    weight = tf.random_normal(weight_shape, stddev=0.1)\n",
    "    # Initialize the bias\n",
    "    bias = tf.random_normal(shape=[num_outputs])\n",
    "    # Now make the flat 1D array into a 2D array for multiplication\n",
    "    input_2d = tf.expand_dims(flat_input, 0)\n",
    "    # Multiply and add the bias\n",
    "    full_output = tf.add(tf.matmul(input_2d, weight), bias)\n",
    "    # Get rid of extra dimension\n",
    "    full_output_2d = tf.squeeze(full_output)\n",
    "    return(full_output_2d)\n",
    "\n",
    "# Create Fully Connected Layer\n",
    "my_full_output = fully_connected(my_maxpool_output, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> 2D Data <<<<\n",
      "Input = [10, 10] array\n",
      "[2, 2] Convolution, stride size = [2, 2] , results in the [5, 5] array\n",
      "[[ 0.14431179  0.72783369  1.51149166 -1.28099763  1.78439188]\n",
      " [-2.54503059  0.76156765 -0.51650006  0.77131093  0.37542343]\n",
      " [ 0.49345911  0.01592223  0.38653135 -1.47997665  0.6952765 ]\n",
      " [-0.34617192 -2.53189754 -0.9525758  -1.4357065   0.66257358]\n",
      " [-1.98540258  0.34398788  2.53760481 -0.86784822 -0.3100495 ]]\n",
      "\n",
      "Input = the above [5, 5] array\n",
      "ReLU element wise returns the [5, 5] array\n",
      "[[ 0.14431179  0.72783369  1.51149166  0.          1.78439188]\n",
      " [ 0.          0.76156765  0.          0.77131093  0.37542343]\n",
      " [ 0.49345911  0.01592223  0.38653135  0.          0.6952765 ]\n",
      " [ 0.          0.          0.          0.          0.66257358]\n",
      " [ 0.          0.34398788  2.53760481  0.          0.        ]]\n",
      "\n",
      "Input = the above [5, 5] array\n",
      "MaxPool, stride size = [1, 1], results in [4, 4] array\n",
      "[[ 0.76156765  1.51149166  1.51149166  1.78439188]\n",
      " [ 0.76156765  0.76156765  0.77131093  0.77131093]\n",
      " [ 0.49345911  0.38653135  0.38653135  0.6952765 ]\n",
      " [ 0.34398788  2.53760481  2.53760481  0.66257358]]\n",
      "\n",
      "Input = the above [4, 4] array\n",
      "Fully connected layer on all 4 rows results in 5 outputs:\n",
      "[ 0.08245847 -0.16351229 -0.55429065 -0.24322605 -0.99900764]\n"
     ]
    }
   ],
   "source": [
    "# Run graph\n",
    "# Initialize Variables\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "feed_dict = {x_input_2d: data_2d}\n",
    "\n",
    "print('>>>> 2D Data <<<<')\n",
    "\n",
    "# Convolution Output\n",
    "print('Input = %s array' % (x_input_2d.shape.as_list()))\n",
    "print('%s Convolution, stride size = [%d, %d] , results in the %s array' % \n",
    "      (my_filter.get_shape().as_list()[:2],conv_stride_size,conv_stride_size,my_convolution_output.shape.as_list()))\n",
    "print(sess.run(my_convolution_output, feed_dict=feed_dict))\n",
    "\n",
    "# Activation Output\n",
    "print('\\nInput = the above %s array' % (my_convolution_output.shape.as_list()))\n",
    "print('ReLU element wise returns the %s array' % (my_activation_output.shape.as_list()))\n",
    "print(sess.run(my_activation_output, feed_dict=feed_dict))\n",
    "\n",
    "# Max Pool Output\n",
    "print('\\nInput = the above %s array' % (my_activation_output.shape.as_list()))\n",
    "print('MaxPool, stride size = [%d, %d], results in %s array' % \n",
    "      (maxpool_stride_size,maxpool_stride_size,my_maxpool_output.shape.as_list()))\n",
    "print(sess.run(my_maxpool_output, feed_dict=feed_dict))\n",
    "\n",
    "# Fully Connected Output\n",
    "print('\\nInput = the above %s array' % (my_maxpool_output.shape.as_list()))\n",
    "print('Fully connected layer on all %d rows results in %s outputs:' % \n",
    "      (my_maxpool_output.shape.as_list()[0],my_full_output.shape.as_list()[0]))\n",
    "print(sess.run(my_full_output, feed_dict=feed_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 3 叠加多个全连接层\n",
    "\n",
    "### Low Birthrate data:\n",
    "```\n",
    "#Columns    Variable                                      Abbreviation\n",
    "#---------------------------------------------------------------------\n",
    "# Low Birth Weight (0 = Birth Weight >= 2500g,            LOW\n",
    "#                          1 = Birth Weight < 2500g)\n",
    "# Age of the Mother in Years                              AGE\n",
    "# Weight in Pounds at the Last Menstrual Period           LWT\n",
    "# Race (1 = White, 2 = Black, 3 = Other)                  RACE\n",
    "# Smoking Status During Pregnancy (1 = Yes, 0 = No)       SMOKE\n",
    "# History of Premature Labor (0 = None  1 = One, etc.)    PTL\n",
    "# History of Hypertension (1 = Yes, 0 = No)               HT\n",
    "# Presence of Uterine Irritability (1 = Yes, 0 = No)      UI\n",
    "# Birth Weight in Grams                                   BWT\n",
    "#---------------------------------------------------------------------\n",
    "```\n",
    "The multiple neural network layer we will create will be composed of three fully connected hidden layers, with node sizes 50, 25, and 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import os\n",
    "import os.path\n",
    "import random\n",
    "import numpy as np\n",
    "import random\n",
    "import requests\n",
    "from tensorflow.python.framework import ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create graph session \n",
    "ops.reset_default_graph()\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name of data file\n",
    "birth_weight_file = 'birth_weight.csv'\n",
    "\n",
    "# download data and create data file if file does not exist in current directory\n",
    "if not os.path.exists(birth_weight_file):\n",
    "    birthdata_url = 'https://github.com/nfmcclure/tensorflow_cookbook/raw/master/01_Introduction/07_Working_with_Data_Sources/birthweight_data/birthweight.dat'\n",
    "    birth_file = requests.get(birthdata_url)\n",
    "    birth_data = birth_file.text.split('\\r\\n')\n",
    "    birth_header = birth_data[0].split('\\t')\n",
    "    birth_data = [[float(x) for x in y.split('\\t') if len(x)>=1] for y in birth_data[1:] if len(y)>=1]\n",
    "    with open(birth_weight_file, \"w\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([birth_header])\n",
    "        writer.writerows(birth_data)\n",
    "        f.close()\n",
    "\n",
    "# read birth weight data into memory\n",
    "birth_data = []\n",
    "with open(birth_weight_file, 'r') as csvfile:\n",
    "    csv_reader = csv.reader(csvfile)\n",
    "    birth_header = next(csv_reader)\n",
    "    for row in csv_reader:\n",
    "        birth_data.append(row)\n",
    "\n",
    "birth_data = [[float(x) for x in row] for row in birth_data]\n",
    "\n",
    "\n",
    "# Extract y-target (birth weight)\n",
    "y_vals = np.array([x[8] for x in birth_data])\n",
    "\n",
    "# Filter for features of interest\n",
    "cols_of_interest = ['AGE', 'LWT', 'RACE', 'SMOKE', 'PTL', 'HT', 'UI']\n",
    "newline = np.array([[x[ix] for ix, feature in enumerate(birth_header) if feature in cols_of_interest] for x in birth_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 配置参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set batch size for training\n",
    "batch_size = 100\n",
    "\n",
    "# make results reproducible\n",
    "seed = 3\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 预测处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train/test = 80%/20%\n",
    "train_indices = np.random.choice(len(x_vals), int(round(len(x_vals)*0.8)), replace=False)\n",
    "test_indices = np.array(list(set(range(len(x_vals))) - set(train_indices)))\n",
    "x_vals_train = x_vals[train_indices]\n",
    "x_vals_test = x_vals[test_indices]\n",
    "y_vals_train = y_vals[train_indices]\n",
    "y_vals_test = y_vals[test_indices]\n",
    "\n",
    "\n",
    "# Normalize by column (min-max norm to be between 0 and 1)\n",
    "def normalize_cols(m):\n",
    "    col_max = m.max(axis=0)\n",
    "    col_min = m.min(axis=0)\n",
    "    return (m-col_min) / (col_max - col_min)\n",
    "    \n",
    "x_vals_train = np.nan_to_num(normalize_cols(x_vals_train))\n",
    "x_vals_test = np.nan_to_num(normalize_cols(x_vals_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 创建初始化的函数和全连接层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define Variable Functions (weights and bias)\n",
    "def init_weight(shape, st_dev):\n",
    "    weight = tf.Variable(tf.random_normal(shape, stddev=st_dev))\n",
    "    return(weight)\n",
    "    \n",
    "\n",
    "def init_bias(shape, st_dev):\n",
    "    bias = tf.Variable(tf.random_normal(shape, stddev=st_dev))\n",
    "    return(bias)\n",
    "    \n",
    "    \n",
    "# Create Placeholders\n",
    "x_data = tf.placeholder(shape=[None, 7], dtype=tf.float32)\n",
    "y_target = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n",
    "\n",
    "\n",
    "# Create a fully connected layer:\n",
    "def fully_connected(input_layer, weights, biases):\n",
    "    layer = tf.add(tf.matmul(input_layer, weights), biases)\n",
    "    return(tf.nn.relu(layer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 构建多重全连接层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#--------Create the first layer (50 hidden nodes)--------\n",
    "weight_1 = init_weight(shape=[7, 25], st_dev=10.0)\n",
    "bias_1 = init_bias(shape=[25], st_dev=10.0)\n",
    "layer_1 = fully_connected(x_data, weight_1, bias_1)\n",
    "\n",
    "#--------Create second layer (25 hidden nodes)--------\n",
    "weight_2 = init_weight(shape=[25, 10], st_dev=10.0)\n",
    "bias_2 = init_bias(shape=[10], st_dev=10.0)\n",
    "layer_2 = fully_connected(layer_1, weight_2, bias_2)\n",
    "\n",
    "\n",
    "#--------Create third layer (5 hidden nodes)--------\n",
    "weight_3 = init_weight(shape=[10, 3], st_dev=10.0)\n",
    "bias_3 = init_bias(shape=[3], st_dev=10.0)\n",
    "layer_3 = fully_connected(layer_2, weight_3, bias_3)\n",
    "\n",
    "\n",
    "#--------Create output layer (1 output value)--------\n",
    "weight_4 = init_weight(shape=[3, 1], st_dev=10.0)\n",
    "bias_4 = init_bias(shape=[1], st_dev=10.0)\n",
    "final_output = fully_connected(layer_3, weight_4, bias_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 构建损失函数，优化函数，初始化变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare loss function (L1)\n",
    "loss = tf.reduce_mean(tf.abs(y_target - final_output))\n",
    "\n",
    "# Declare optimizer\n",
    "my_opt = tf.train.AdamOptimizer(0.05)\n",
    "train_step = my_opt.minimize(loss)\n",
    "\n",
    "# Initialize Variables\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation: 25. Loss = 5285.38\n",
      "Generation: 50. Loss = 2714.99\n",
      "Generation: 75. Loss = 2629.44\n",
      "Generation: 100. Loss = 2040.34\n",
      "Generation: 125. Loss = 2334.34\n",
      "Generation: 150. Loss = 1700.53\n",
      "Generation: 175. Loss = 1663.91\n",
      "Generation: 200. Loss = 786.831\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "loss_vec = []\n",
    "test_loss = []\n",
    "for i in range(200):\n",
    "    rand_index = np.random.choice(len(x_vals_train), size=batch_size)\n",
    "    rand_x = x_vals_train[rand_index]\n",
    "    rand_y = np.transpose([y_vals_train[rand_index]])\n",
    "    sess.run(train_step, feed_dict={x_data: rand_x, y_target: rand_y})\n",
    "\n",
    "    temp_loss = sess.run(loss, feed_dict={x_data: rand_x, y_target: rand_y})\n",
    "    loss_vec.append(temp_loss)\n",
    "    \n",
    "    test_temp_loss = sess.run(loss, feed_dict={x_data: x_vals_test, y_target: np.transpose([y_vals_test])})\n",
    "    test_loss.append(test_temp_loss)\n",
    "    if (i+1) % 25 == 0:\n",
    "        print('Generation: ' + str(i+1) + '. Loss = ' + str(temp_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.8 可视化训练的损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEWCAYAAACufwpNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhkXybfv6HAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa2afd09e90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# Plot loss (MSE) over time\n",
    "plt.plot(loss_vec, 'k-', label='Train Loss')\n",
    "plt.plot(test_loss, 'r--', label='Test Loss')\n",
    "plt.title('Loss (MSE) per Generation')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('Generation')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
